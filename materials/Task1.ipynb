{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a578f2ab",
   "metadata": {
    "id": "a578f2ab"
   },
   "source": "# Task 1: Anon"
  },
  {
   "cell_type": "markdown",
   "id": "2251a923",
   "metadata": {
    "id": "2251a923"
   },
   "source": [
    "In this example, we are going to apply [Anon](https://github.com/DataResponsibly/Anon) to conduct a deep performance profiling for three models trained on the [Diabetes Dataset 2019](https://www.kaggle.com/datasets/tigganeha4/diabetes-dataset-2019/data). We will show how to create input arguments for Anon and how to compute overall and disparity metrics with a metric computation interface.\n",
    "\n",
    "The structure of this notebook is the following:\n",
    "* **Step 1**: Create a _config yaml_ for metric computation.\n",
    "* **Step 2**: Preprocess a dataset and construct a _BaseFlowDataset_ object.\n",
    "* **Step 3**: Tune models and create a _models config_.\n",
    "* **Step 4**: Run a metric computation interface from Anon.\n",
    "* **Step 5**: Compose disparity metrics using _Metric Composer_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606df34d",
   "metadata": {
    "id": "606df34d"
   },
   "source": [
    "## Install necessary packages and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668af6f1babe4564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:05:54.988254Z",
     "start_time": "2024-06-02T14:05:54.960443Z"
    },
    "id": "668af6f1babe4564"
   },
   "outputs": [],
   "source": [
    "# Install Anon using pypi. The library supports Python 3.9-3.11.\n",
    "!pip install anon"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install xgboost>=1.7.2"
   ],
   "metadata": {
    "id": "x0Rn5SOod_gS"
   },
   "id": "x0Rn5SOod_gS",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f5cae205d3b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:20.738385Z",
     "start_time": "2024-06-02T14:01:20.333024Z"
    },
    "id": "635f5cae205d3b4f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9241de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:13:58.259297Z",
     "start_time": "2024-06-02T14:13:58.202764Z"
    },
    "id": "7a9241de"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from anon.utils.custom_initializers import create_config_obj, read_model_metric_dfs\n",
    "from anon.user_interfaces.multiple_models_api import compute_metrics_with_config\n",
    "from anon.preprocessing.basic_preprocessing import preprocess_dataset\n",
    "from anon.custom_classes.metrics_interactive_visualizer import MetricsInteractiveVisualizer\n",
    "from anon.custom_classes.metrics_visualizer import MetricsVisualizer\n",
    "from anon.custom_classes.metrics_composer import MetricsComposer\n",
    "from anon.utils.model_tuning_utils import tune_ML_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ef968c9937432",
   "metadata": {
    "collapsed": false,
    "id": "154ef968c9937432"
   },
   "source": [
    "## **Step 1**: Create a _config yaml_ for metrics computation."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Review the dataset."
   ],
   "metadata": {
    "id": "XVA49O4nWRTz"
   },
   "id": "XVA49O4nWRTz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd69e89d33f3e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:24.193309Z",
     "start_time": "2024-06-02T14:01:22.898511Z"
    },
    "id": "7bd69e89d33f3e08"
   },
   "outputs": [],
   "source": [
    "from anon.datasets import DiabetesDataset2019\n",
    "\n",
    "data_loader = DiabetesDataset2019(with_nulls=False, subsample_seed=42)\n",
    "data_loader.full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae47aed99d5ba8d",
   "metadata": {
    "collapsed": false,
    "id": "8ae47aed99d5ba8d"
   },
   "source": [
    "First, we need to create a _config yaml_, which includes the following parameters for metrics computation:\n",
    "\n",
    "* **dataset_name**: str, a name of the dataset; it will be used to name files with metrics.\n",
    "\n",
    "* **bootstrap_fraction**: float, the fraction from a train set in the range [0.0 - 1.0] to fit models in bootstrap (usually more than 0.5).\n",
    "\n",
    "* **random_state**: int, a seed to control the randomness of the whole model evaluation pipeline.\n",
    "\n",
    "* **n_estimators**: int, the number of estimators for bootstrap to compute stability and uncertainty metrics.\n",
    "\n",
    "* **sensitive_attributes_dct**: dict, a dictionary where keys are sensitive attribute names (including intersectional attributes), and values are disadvantaged values for these attributes. Intersectional attributes must include '&' between sensitive attributes. You do not need to specify disadvantaged values for intersectional groups since they will be derived from disadvantaged values in sensitive_attributes_dct for each separate sensitive attribute in this intersectional pair."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **TODO 1**: Define one sensitive group in the *sensitive_attributes_dct* section of the *experiment_config.yaml*. Explain why the selected sensitive attribute is appropriate for this prediction task and its context.\n",
    "\n",
    "**Hint:** Do NOT use \"Age\" as a sensitive attribute. Age is a real clinical risk factor for diabetes, so enforcing equal rates across age groups would be misleading.\n",
    "\n",
    "To decide on `<SENSITIVE_ATTRIBUTE>` and `<DISADVANTAGED_VALUE>`, you may review:\n",
    "- The **Kaggle Diabetes Dataset 2019** page:  \n",
    "  https://www.kaggle.com/datasets/tigganeha4/diabetes-dataset-2019/data  \n",
    "  (this helps you understand the distribution of each column)\n",
    "- The previously shared **Tutorial Notes**:  \n",
    "  https://drive.google.com/file/d/1BmXdxEEFiRM19Ny7V3hjEemnLmiFnbVc/view?usp=sharing  \n",
    "  (for definitions and contextual meaning)\n",
    "\n",
    "Note that within the *sensitive_attributes_dct:*\n",
    "- key is the column name in the dataset\n",
    "- value is the disadvantaged value withing this column; it can be a literal or a list, see examples below.\n",
    "\n",
    "```\n",
    "sensitive_attributes_dct: {'sex': 'female'}\n",
    "```\n",
    "\n",
    "```\n",
    "sensitive_attributes_dct: {'age': [19, 20, 21, 22, 23, 24, 25]}\n",
    "```\n"
   ],
   "metadata": {
    "id": "dwtEMi4GmEVL"
   },
   "id": "dwtEMi4GmEVL"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd56e951b5fd132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:22.872204Z",
     "start_time": "2024-06-02T14:01:22.844817Z"
    },
    "id": "bbd56e951b5fd132"
   },
   "outputs": [],
   "source": [
    "config_yaml_path = os.path.join('.', 'experiment_config.yaml')\n",
    "config_yaml_content = \"\"\"\n",
    "dataset_name: Diabetes_2019\n",
    "bootstrap_fraction: 0.8\n",
    "random_state: 42\n",
    "n_estimators: 20  # Better to input the higher number of estimators than 100; this is only for this user study\n",
    "sensitive_attributes_dct: {'<SENSITIVE_ATTRIBUTE>': '<DISADVANTAGED_VALUE>'}\n",
    "\"\"\"\n",
    "\n",
    "with open(config_yaml_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd18d315063a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:22.902168Z",
     "start_time": "2024-06-02T14:01:22.873186Z"
    },
    "id": "b2fd18d315063a47"
   },
   "outputs": [],
   "source": [
    "config = create_config_obj(config_yaml_path=config_yaml_path)\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join('.', 'results', f'{config.dataset_name}_Metrics_{datetime.now(timezone.utc).strftime(\"%Y%m%d__%H%M%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Briefly write your answer in the Google form***"
   ],
   "metadata": {
    "id": "ZGZ4r1hxbVGm"
   },
   "id": "ZGZ4r1hxbVGm"
  },
  {
   "cell_type": "markdown",
   "id": "8c633b771e77945a",
   "metadata": {
    "collapsed": false,
    "id": "8c633b771e77945a"
   },
   "source": [
    "## **Step 2**: Preprocess the dataset and construct a _BaseFlowDataset_ object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93793c51964f51",
   "metadata": {
    "collapsed": false,
    "id": "5f93793c51964f51"
   },
   "source": [
    "Second, we need to preprocess the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fbf1fe5834390",
   "metadata": {
    "collapsed": false,
    "id": "987fbf1fe5834390"
   },
   "source": [
    "Define preprocessing steps and initialize a column transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158baf3f0853864e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:24.204251Z",
     "start_time": "2024-06-02T14:01:24.162607Z"
    },
    "id": "158baf3f0853864e"
   },
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore', sparse_output=False), data_loader.categorical_columns),\n",
    "    ('numerical_features', StandardScaler(), data_loader.numerical_columns),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa9c791d08d504",
   "metadata": {
    "collapsed": false,
    "id": "6eaa9c791d08d504"
   },
   "source": [
    "Construct a BaseFlowDataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b893a804b4bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:24.324734Z",
     "start_time": "2024-06-02T14:01:24.188842Z"
    },
    "id": "213b893a804b4bd6"
   },
   "outputs": [],
   "source": [
    "DATASET_SPLIT_SEED = 42\n",
    "MODELS_TUNING_SEED = 42\n",
    "TEST_SET_FRACTION = 0.2\n",
    "\n",
    "base_flow_dataset = preprocess_dataset(data_loader=data_loader,\n",
    "                                       column_transformer=column_transformer,\n",
    "                                       sensitive_attributes_dct=config.sensitive_attributes_dct,\n",
    "                                       test_set_fraction=TEST_SET_FRACTION,\n",
    "                                       dataset_split_seed=DATASET_SPLIT_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483da592b29ba485",
   "metadata": {
    "collapsed": false,
    "id": "483da592b29ba485"
   },
   "source": [
    "## **Step 3**: Tune models and create a _models config_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990330e9d7da5e70",
   "metadata": {
    "collapsed": false,
    "id": "990330e9d7da5e70"
   },
   "source": "Next, we need to construct a _models config_ that includes initialized models you want to profile with Anon. For that, the models should be tuned using the _tune_ML_models()_ function from Anon or in any other convenient way."
  },
  {
   "cell_type": "markdown",
   "id": "660af59469317200",
   "metadata": {
    "collapsed": false,
    "id": "660af59469317200"
   },
   "source": [
    "Define models and hyper-parameters to tune using GridSearchCV from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1badaf3e65e97e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:24.599986Z",
     "start_time": "2024-06-02T14:01:24.290509Z"
    },
    "id": "e1badaf3e65e97e"
   },
   "outputs": [],
   "source": [
    "models_params_for_tuning = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=MODELS_TUNING_SEED),\n",
    "        'params': {\n",
    "            'penalty': ['l2'],\n",
    "            'C' : [0.0001, 0.1, 1, 100],\n",
    "            'solver': ['newton-cg', 'lbfgs'],\n",
    "            'max_iter': [250],\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'weights' : ['uniform'],\n",
    "            'algorithm' : ['auto'],\n",
    "            'n_neighbors' : [3, 4, 5],\n",
    "        }\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'model': XGBClassifier(random_state=MODELS_TUNING_SEED, verbosity=0),\n",
    "        'params': {\n",
    "            'learning_rate': [0.1],\n",
    "            'n_estimators': [50],\n",
    "            'max_depth': [5, 7],\n",
    "            'lambda':  [10, 100]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a267ffdf55fa180",
   "metadata": {
    "collapsed": false,
    "id": "5a267ffdf55fa180"
   },
   "source": "Tune models using the _tune_ML_models()_ function from Anon and create the _models config_."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7577ac3a3fb389d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:53.850562Z",
     "start_time": "2024-06-02T14:01:24.314934Z"
    },
    "id": "a7577ac3a3fb389d"
   },
   "outputs": [],
   "source": [
    "tuned_params_df, models_config = tune_ML_models(models_params_for_tuning, base_flow_dataset, dataset_name='Diabetes_2019', n_folds=3)\n",
    "tuned_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb83f9f76ab5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:01:53.957346Z",
     "start_time": "2024-06-02T14:01:53.847255Z"
    },
    "id": "9bcb83f9f76ab5b"
   },
   "outputs": [],
   "source": [
    "pprint(models_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cc6f1",
   "metadata": {
    "id": "3b8cc6f1"
   },
   "source": [
    "### **TODO 2:** Based on these accuracy metrics, which model would you choose for this classification task? Can you say anything about who may be disadvantaged and in what way when the model makes an error?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Briefly write your answer in the Google form***"
   ],
   "metadata": {
    "id": "1QygnW1yemmY"
   },
   "id": "1QygnW1yemmY"
  },
  {
   "cell_type": "markdown",
   "id": "bf80fdad007c7456",
   "metadata": {
    "collapsed": false,
    "id": "bf80fdad007c7456"
   },
   "source": "## **Step 4**: Run a metric computation interface from Anon."
  },
  {
   "cell_type": "markdown",
   "id": "52622dd736aa6046",
   "metadata": {
    "collapsed": false,
    "id": "52622dd736aa6046"
   },
   "source": [
    "After that we need to input the _BaseFlowDataset_ object, _models config_, and _config yaml_ to a metric computation interface and execute it. The interface uses subgroup analyzers to compute different sets of metrics for each privileged and disadvantaged group. When the variance and error analyzers complete metric computation, their metrics are combined, returned in a matrix format, and stored in a file if defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846f004634b1c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:03:24.852725Z",
     "start_time": "2024-06-02T14:01:53.895989Z"
    },
    "id": "5846f004634b1c5a"
   },
   "outputs": [],
   "source": [
    "metrics_dct = compute_metrics_with_config(base_flow_dataset, config, models_config, SAVE_RESULTS_DIR_PATH, notebook_logs_stdout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93587127",
   "metadata": {
    "id": "93587127"
   },
   "source": [
    "### **TODO 3:** Fill in the index of your chosen model below from the table in step 3, and run to see some more comprehensive metrics for the protected classes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c57986",
   "metadata": {
    "id": "72c57986"
   },
   "outputs": [],
   "source": [
    "model_index ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085d612eca8e69f",
   "metadata": {
    "collapsed": false,
    "id": "e085d612eca8e69f"
   },
   "source": [
    "View the computed metrics for one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5944783bc37d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:03:24.889615Z",
     "start_time": "2024-06-02T14:03:24.852962Z"
    },
    "id": "4f5944783bc37d08"
   },
   "outputs": [],
   "source": [
    "sample_model_metrics_df = metrics_dct[list(models_config.keys())[model_index]]\n",
    "sample_model_metrics_df[(sample_model_metrics_df['Metric'] == \"TPR\") | (sample_model_metrics_df['Metric'] == \"TNR\") | (sample_model_metrics_df['Metric'] == \"PPV\") | (sample_model_metrics_df['Metric'] == \"FPR\") | (sample_model_metrics_df['Metric'] == \"FNR\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b42592",
   "metadata": {
    "id": "44b42592"
   },
   "source": [
    "### **TODO 4:** Consider your chosen model's error rates (FPR, FNR) for the protected classes. Does your model further disadvantage the already disadvantaged group? (note that _priv denotes the privileged group and _dis denotes the disadvantaged group for each protected class)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Briefly write your answer in the Google form***"
   ],
   "metadata": {
    "id": "cdHupLQbexoW"
   },
   "id": "cdHupLQbexoW"
  },
  {
   "cell_type": "markdown",
   "id": "b63982cb",
   "metadata": {
    "id": "b63982cb"
   },
   "source": [
    "### **TODO 5:** Select any additional model. Fill in model names to compare additional metrics for protected classes against those of your original model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Briefly write your answers on the following questions in the Google form:***\n",
    "\n",
    "\n",
    "*   **Would you change your original choice? Why or why not?**\n",
    "\n"
   ],
   "metadata": {
    "id": "80KRmlQ4db1N"
   },
   "id": "80KRmlQ4db1N"
  },
  {
   "cell_type": "code",
   "source": [
    "chosen_model, additional_model = '<ORIGINALLY_CHOSEN_MODEL_NAME>', '<ADDITIONAL_MODEL_NAME>'\n",
    "\n",
    "df_concat = pd.concat([metrics_dct[chosen_model], metrics_dct[additional_model]], keys=[chosen_model, additional_model])\n",
    "df_concat = df_concat.reset_index()\n",
    "\n",
    "metrics = ['Accuracy', 'F1', 'TPR', 'TNR', 'FPR', 'FNR']\n",
    "sensitive_attr = list(config.sensitive_attributes_dct.keys())[0]\n",
    "df_pivot = df_concat.pivot(\n",
    "    index='Metric',\n",
    "    columns='Model_Name',\n",
    "    values=['overall', f'{sensitive_attr}_priv', f'{sensitive_attr}_dis']\n",
    ")\n",
    "df_pivot.loc[metrics]"
   ],
   "metadata": {
    "id": "gzuN2zquN2Wr"
   },
   "id": "gzuN2zquN2Wr",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "106780dbeffce346",
   "metadata": {
    "collapsed": false,
    "id": "106780dbeffce346"
   },
   "source": [
    "## **Step 5**: Compose disparity metrics using _Metric Composer_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee25ee4d75200ba",
   "metadata": {
    "collapsed": false,
    "id": "cee25ee4d75200ba"
   },
   "source": [
    "To compose disparity metrics, the _Metric Composer_ should be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356161cf3fa140ce",
   "metadata": {
    "collapsed": false,
    "id": "356161cf3fa140ce"
   },
   "source": [
    "Read the computed metrics from a file created by the metric computation interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c0e14df975b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:03:24.921061Z",
     "start_time": "2024-06-02T14:03:24.887747Z"
    },
    "id": "228c0e14df975b62"
   },
   "outputs": [],
   "source": [
    "models_metrics_dct = read_model_metric_dfs(SAVE_RESULTS_DIR_PATH, model_names=list(models_config.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a597baac4d86943",
   "metadata": {
    "collapsed": false,
    "id": "8a597baac4d86943"
   },
   "source": [
    "Compose disparity metrics using _MetricsComposer_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9befb603132bb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:03:24.998457Z",
     "start_time": "2024-06-02T14:03:24.915871Z"
    },
    "id": "fb9befb603132bb8"
   },
   "outputs": [],
   "source": [
    "metrics_composer = MetricsComposer(models_metrics_dct, config.sensitive_attributes_dct)\n",
    "models_composed_metrics_df = metrics_composer.compose_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537f2da",
   "metadata": {
    "id": "e537f2da"
   },
   "source": [
    "### **TODO 6:** Fill in the *model_name* variable with the model you chose in TODO 4 and calculate fairness metrics. Then answer: Does this model demonstrate satisfactory fairness? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Hint:* Values closer to zero are better."
   ],
   "metadata": {
    "id": "XF3tQNFk8f6G"
   },
   "id": "XF3tQNFk8f6G"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025eaa778c0012b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T14:03:25.000035Z",
     "start_time": "2024-06-02T14:03:24.955405Z"
    },
    "id": "2025eaa778c0012b"
   },
   "outputs": [],
   "source": [
    "# models_composed_metrics_df\n",
    "model_name = ''\n",
    "\n",
    "models_composed_metrics_df = models_composed_metrics_df[models_composed_metrics_df['Model_Name'] == model_name]\n",
    "models_composed_metrics_df[(models_composed_metrics_df['Metric'] == 'Accuracy_Difference') | (models_composed_metrics_df['Metric'] == 'Equalized_Odds_FPR') | (models_composed_metrics_df['Metric'] == 'Equalized_Odds_FNR')]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Briefly write your answer in the Google form***"
   ],
   "metadata": {
    "id": "a0IpX8S1hhgr"
   },
   "id": "a0IpX8S1hhgr"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1hJUz4wLSdn3a1K5s-XJ1IAifrVXy85hv",
     "timestamp": 1763730877727
    }
   ]
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

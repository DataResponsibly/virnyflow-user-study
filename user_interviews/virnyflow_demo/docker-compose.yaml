version: '3'

networks:
  task-manager-network:
    driver: bridge

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local

services:
  zookeeper:
    image: bitnamilegacy/zookeeper:3.8.4-debian-12-r9
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    networks:
      - task-manager-network

  kafka_broker:
    image: bitnamilegacy/kafka:3.3.2-debian-11-r11
    container_name: kafka_broker
    environment:
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT_INTERNAL://0.0.0.0:9092,PLAINTEXT_EXTERNAL://0.0.0.0:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT_INTERNAL://kafka_broker:9092,PLAINTEXT_EXTERNAL://localhost:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT_INTERNAL
      - KAFKA_CFG_GROUP_MIN_SESSION_TIMEOUT_MS=6000
      - KAFKA_CFG_GROUP_MAX_SESSION_TIMEOUT_MS=600000
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_OFFSETS_TOPIC_NUM_PARTITIONS=1
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    ports:
      - "9092:9092"
      - "9093:9093"
    depends_on:
      - zookeeper
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - task-manager-network

  init-kafka:
    image: confluentinc/cp-kafka:6.1.1
    networks:
      - task-manager-network
    depends_on:
      - kafka_broker
    entrypoint: [ "/bin/sh", "-c" ]
    command: |
      "
      # wait until the broker is reachable
      until kafka-topics --bootstrap-server kafka_broker:9092 --list >/dev/null 2>&1; do
        echo 'Waiting for kafka_broker:9092...'
        sleep 3
      done

      echo 'Creating kafka topics (if missing)'
      kafka-topics --bootstrap-server kafka_broker:9092 --create --if-not-exists --topic NewTasksQueue --replication-factor 1 --partitions 2
      kafka-topics --bootstrap-server kafka_broker:9092 --create --if-not-exists --topic CompletedTasksQueue --replication-factor 1 --partitions 2

      echo 'Topics present:'
      kafka-topics --bootstrap-server kafka_broker:9092 --list
      "

  task-manager:
    build:
      context: .
      dockerfile: Dockerfile_VirnyFlow
    ports:
      - "8000:8000"
    networks:
      - task-manager-network
    command: >
      /bin/sh -c "echo 'Waiting for Kafka coordinator to be ready...'; sleep 40; python run_task_manager.py"

  worker:
    build:
      context: .
      dockerfile: Dockerfile_VirnyFlow
    networks:
      - task-manager-network
    command: >
      /bin/sh -c "echo 'Waiting for Kafka coordinator to be ready...'; sleep 40; python run_worker.py"
    deploy:
      replicas: 2  # This should be the same as an optimisation_args.num_workers parameter in exp_config.yaml

  virnyflow-interface:
    build:
      context: .
      dockerfile: Dockerfile_Interface
      args:
        # override these if you want to point to another Space/branch
        SPACE_URL: https://huggingface.co/spaces/denys-herasymuk/virnyflow-demo
        SPACE_BRANCH: main
    ports:
      - "7860:7860"   # host:container
    environment:
      # Optional: you can pass a custom config file to the app if needed
      # The app also accepts --exp_config_path; see command below.
      GRADIO_SERVER_NAME: 0.0.0.0
      GRADIO_SERVER_PORT: 7860
    command: >
      /bin/sh -c "set -a && . ./configs/secrets.env && set +a && sleep 90 && python app.py --exp_config_path ./exp_config.yaml"
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 7860)); print('ok')"]
      interval: 10s
      timeout: 5s
      retries: 5
